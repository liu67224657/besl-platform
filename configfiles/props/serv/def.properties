
###########################################################################
# The following settings (prefixed with server.qwrite) are used by practially
# all servers. They control wedged conn checking and the number of write
# threads used to send responses to clients.
#
# Most servers are fine with these default settings, but some servers
# might want to set them to different values. In particular, if a server
# wants to turn this feature off altogether, it can set 
# server.qwrite.nthreads to 0.
###########################################################################
#
# This setting establishes the number of write threads to use.
# In general, you don't need many. If you want to turn off wedge-checking
# and queuing of write requests, set this value to 0.
#
server.qwrite.nthreads=0

# This value is the number of seconds to sleep between checking to see if
# we have any wedged conns. A separate thread wakes every 
# server.qwrite.checkInterval seconds running through the list of conns
# to see if we have a wedge.
#
server.qwrite.checkInterval=10

# This value is how long a socketWrite() operation needs to hang before
# we consider the conn wedged. The value is in seconds. Normally packets
# written to sockets should be handled right away, on the order of msecs.
# Most servers will be fine with something like 10 seconds, but servers
# that send huge packets might want to adjust these parameters.
#
server.qwrite.timeout=10

#
# The period for rate limiting transactions that fail due to resource
# limiting. The value is in seconds. NOTE: not all servers make use
# of these settings, but a few do.
#
server.resourceLimit.period=3600

#
# The max number of failed requests during the above period after which
# we begin fast failing the transactions.
#
server.resourceLimit.maxRequests=10

#
# This property enables fast-fail of requests within an app-server if
# the pool of request threads is backed up and not processing any more
# incoming requests. Internall a queue is used to store the incoming
# requests, and if that queue is backing up, and the server has not
# processed a packet in server.fastFailTimeoutSecs, then we consider
# the server to be overloaded and the caller will get a 
# ServiceException.OVERLOADED.
#
# This feature can be disabled by setting the property to 0 (in this
# case the behavior is that the conn thread will block until a request
# thread becomes available).
#
server.fastFailTimeoutSecs=60
#
# If server.fastFailTimeoutSecs<>0, then this property is also used.
# This controls how big to let the queue get regardless of whether the
# requests are being serviced. If this size is exceeded, the server will
# throw OVERLOADED exceptions. This typically will mean that the server
# is overloaded and that a client normally receiving a TIMEOUT will
# now receive OVERLOADED.
#
server.fastFailMaxQueueSize=1000


###########################################
#the cache setting.
###########################################
mdcache.manager.updateCheck=true
mdcache.manager.maxBytesOnHeap=1g
mdcache.manager.Monitoring=autodetect
mdcache.manager.dynamicConfig=false

###########################################
#the cache setting.
###########################################
kafka.producer.metadata.broker.list=
kafka.zookeeper.connect=
kafka.group.id=
kafka.topic=
kafka.serializer.class=kafka.serializer.StringEncoder
#kafka.serializer.StringEncoder
kafka.key.serializer.class=org.apache.kafka.common.serialization.StringSerializer
kafka.value.serializer.class=org.apache.kafka.common.serialization.StringSerializer
kafka.partitioner.class=com.catt.kafka.demo.PartitionerDemo
kafka.request.required.acks=1
kafka.zookeeper.session.timeout.ms=400
kafka.zookeeper.sync.time.ms=200
kafka.auto.commit.interval.ms=1000
